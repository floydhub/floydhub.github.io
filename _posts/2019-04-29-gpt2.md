---
layout: post
title: "How to Build OpenAI's GPT-2: \"The AI That Was Too Dangerous to Release\""
date: 2019-04-29 13:41:58 +0000
slug: gpt2
author: Ajay Uppili Arasanipalai
excerpt: "The Key Insights Behind the Greatest Language Model of all Time"
feature_image: "/assets/images/content/images/2019/04/martin-adams-692514-unsplash.jpg"
tags: [gpt-2, nlp, language-models, openai, deep-learning]
---

> Today, the United Nations has called for the immediate withdrawal of all nuclear weapons from the world.

The sentence you just read wasn‚Äôt written by me, the author of this article, nor was it written by the editor. No. What you just read was written entirely by [OpenAI‚Äôs GPT-2 language model](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), prompted only with the word ‚ÄúToday‚Äù.

Apart from another fancy acronym, GPT-2 brought along somewhat coherent (semantically, at least) language generation capabilities, some semblance of hope for zero-shot transfer learning, and a [transformer network](https://floydhub.github.io/the-transformer-in-pytorch/) trained with approximately 1.5 _billion_ parameters on a text corpus with over 40 _gigabytes_ of internet wisdom.

That‚Äôs kind of a big deal.

But of course, what really broke the internet was talking, four-horned, half-breed unicorns in the Andes‚Ä¶

![A text generation sample from OpenAI‚Äôs GPT-2 language model](https://paper-attachments.dropbox.com/s_972195A84441142620E4C92312EA63C9665C3A86AFFD1D713034FA568ADFC5F9_1554959568420_Screenshot+2019-04-11+at+10.42.18+AM.png)A text generation sample from OpenAI‚Äôs GPT-2 language model

In this post, I‚Äôm not going to talk about [better language models and their implications](https://openai.com/blog/better-language-models/). As the great Stan Lee once said, ‚Äúnuff said‚Äù about that.

Here, I‚Äôll show you how exactly humanity‚Äôs greatest text generator (at the time of this writing, at least) works, and how to build your own in just a few lines of code.

Note, however, that the GPT-2 model that we‚Äôre going to build won‚Äôt start generating fake Brexit campaigns. The original model was trained for months, harnessing the power of 100+ GPUs.

So unless you‚Äôve got that kind of computing power, it‚Äôs a feat if your mini-GPT can get subject-verb agreement right.

### Ready to build, train, and deploy AI?

#### Get started with FloydHub's collaborative AI platform for free

###### [Try FloydHub for free ](https://www.floydhub.com/?utm_source=blog&utm_medium=banner-gpt-2&utm_campaign=try_floydhub_for_free)

# What GPT-2 Actually Is

As has become the norm when there is a breakthrough in deep learning research, there‚Äôs been a fair share of terminator imagery accompanying popular articles that describe OpenAI‚Äôs latest set of matrix multiplications. So I thought I‚Äôll start by clearing a few things up.

GPT-2 stands for ‚ÄúGenerative Pretrained Transformer 2‚Äù:

  * ‚Äú**Generative** ‚Äù means the model was trained to predict (or ‚Äúgenerate‚Äù) the next token in a sequence of tokens in an unsupervised way. In other words, the model was thrown a whole lot of raw text data and asked to figure out the statistical features of the text to create more text.
  * ‚Äú**Pretrained** ‚Äù means OpenAI created a large and powerful language model, which they fine-tuned for specific tasks like machine translation later on. This is kind of like transfer learning with Imagenet, except it‚Äôs for NLP. This retraining approach became quite popular in 2018 and is very likely to be a [trend that continues throughout 2019](https://floydhub.github.io/ten-trends-in-deep-learning-nlp/).
  * ‚Äú**Transformer** ‚Äù means OpenAI used the [transformer architecture](https://floydhub.github.io/the-transformer-in-pytorch/), as opposed to an [RNN](https://karpathy.github.io/2015/05/21/rnn-effectiveness/), [LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/), [GRU](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be) or any other 3/4 letter acronym you have in mind. I‚Äôm not going to discuss the transformer architecture in detail since there‚Äôs already another [great article](https://floydhub.github.io/the-transformer-in-pytorch/) on the FloydHub blog that explains how it works.
  * ‚Äú**2** ‚Äù means this isn‚Äôt the [first time they‚Äôre trying this whole GPT thing out](https://openai.com/blog/language-unsupervised/).

# How it Works

So here‚Äôs a summary of all the 2018 NLP breakthroughs that you need to understand before getting into GPT-2. I‚Äôll illustrate it using some insanely advanced math:

**2018**

![OpenAI Transformer v1 \(aka GPT-1\) = ULMFiT + Transformer](https://paper-attachments.dropbox.com/s_972195A84441142620E4C92312EA63C9665C3A86AFFD1D713034FA568ADFC5F9_1555421423421_OpenAI+Transformer.png) OpenAI Transformer v1(akaGPT-1) = [ULMFiT](https://nlp.fast.ai/classification/2018/05/15/introducing-ulmfit.html)\+ Transformer

**2019**

![GPT-2 = GPT-1 + reddit + A lot of compute](https://paper-attachments.dropbox.com/s_972195A84441142620E4C92312EA63C9665C3A86AFFD1D713034FA568ADFC5F9_1555423661299_GPT2.png) GPT-2 = GPT-1 + reddit + A lot of compute

Wait, What!?

Ok. there‚Äôs a fair amount of background knowledge required to get all of that. To top that, I‚Äôve also left out essential ideas like ELMo and BERT that while not immediately relevant when talking about GPT-2, were instrumental to its eventual development.

If you‚Äôre already aware of the technologies that led up to GPT-2, congratulations! You basically now understand what it takes to invent a state of the art NLP model! üéâüéâ

But for the rest of you that were daydreaming about a Sesame Street-Michael Bay crossover, let‚Äôs get into it.

## Transformers

![Source](https://paper-attachments.dropbox.com/s_972195A84441142620E4C92312EA63C9665C3A86AFFD1D713034FA568ADFC5F9_1554959891978_transformerssh.jpg)[Source](https://cdn3-www.superherohype.com/assets/uploads/2013/11/transformerssh.jpg)

The transformer is an awesome neural network architecture. As I mentioned already, the details of this model are ‚Ä¶ fairly detailed.

So for the purposes of this article, treat the transformer as a black box‚Äî it defines a structure for performing computations. Though in actuality, that‚Äôs a gross abstraction, so I‚Äôd encourage you to read [this](https://floydhub.github.io/the-transformer-in-pytorch/) transformer article before you continue.

## Pre-trained Language Models

![Photo by Kelly Sikkema](https://images.unsplash.com/photo-1549301019-a331aee4f3a3?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjI2NzI5fQ)Photo by [Kelly Sikkema](https://unsplash.com/photos/et5mfj1eB94?utm_source=dropbox_paper&utm_medium=referral)

[Another trend](https://floydhub.github.io/ten-trends-in-deep-learning-nlp/#5-transfer-learning-will-play-more-of-a-role) that the NLP community picked up in 2018 was the idea of transfer learning, which had been going on for years in the computer vision world, but has only recently picked up the pace for NLP tasks. Again, transfer learning has been hugely successful and is likely to continue throughout 2019.

‚ÄúTransfer learning‚Äù here is usually done in 2 ways: feature-based and [fine-tuning](https://floydhub.github.io/ten-trends-in-deep-learning-nlp/#6-fine-tuning-models-will-get-easier).

ELMo uses a feature-based method, where contextual word embeddings are created by concatenating the hidden state vectors from a pretrained language model to the existing word vector. But I‚Äôm not going to elaborate on that, because neither BERT nor GPT use the feature-based approach.

Throughout 2018, we‚Äôve come to see that fine-tuning works slightly better, probably because it allows you to tweak the language model through backpropagation.

## Transformers + Pre-trained Language Models

![Photo by Rafaela Biazi](https://images.unsplash.com/photo-1518117940395-1ac64e773a75?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjI2NzI5fQ)Photo by [Rafaela Biazi](https://unsplash.com/photos/2N1lJCLrCj0?utm_source=dropbox_paper&utm_medium=referral)

So here was OpenAI‚Äôs big insight: transformers work pretty good, Fine-tuning a language model works pretty good, so a transformer + a pretrained language model should work pretty good.

A few backprops later, GPT was born.

In reality, though, there were a few hurdles to cross. First, looking at the transformer architecture, it‚Äôs not entirely clear how to make it work for language modeling. Take a look at the diagram below to see what I mean.

![Source](https://paper-attachments.dropbox.com/s_972195A84441142620E4C92312EA63C9665C3A86AFFD1D713034FA568ADFC5F9_1555423861808_the_transformer_3.png)[Source](http://jalammar.github.io/images/t/the_transformer_3.png)

The transformer expects a complete sentence (‚Äúsentence‚Äù here is not the same as an English sentence, it means a sequence of words of some fixed length ‚Äî 512 in the case of GPT), which it encodes and ‚Äútransforms‚Äù using a decoder.

This behavior makes it an excellent choice for sequence-to-sequence applications, like machine translation and question answering, but it‚Äôs practically useless for language modeling, where we want to predict the next word given a sequence of words.

Luckily, the decoder part of the transformer can sort of do this on its own. Think about what the decoder is actually doing ‚Äî given an encoded representation of a sequence, it generates a new sequence word by word.

Written concretely,

$$\text{word}_t = \text{Decoder}(\text{word}_{t-1},\text{encoding})$$

If we throw away the encoding part from the decoder, we get this:

$$\text{word}_t = \text{Decoder}(\text{word}_{t-1})$$

Which is precisely what a language model is supposed to do!

Consequently, we need to throw away the entire encoder section of the transformer so our final architecture will look like this:

![Source](https://paper-attachments.dropbox.com/s_972195A84441142620E4C92312EA63C9665C3A86AFFD1D713034FA568ADFC5F9_1555423950294_openai-transformer-language-modeling.png)[Source](http://jalammar.github.io/images/openai-transformer-language-modeling.png)

To summarize, GPT is nothing but the decoder part of a regular transformer network, with all the references to the encoder thrown away.

## Fine-tuning GPT

![Photo by Jiroe](https://images.unsplash.com/photo-1517273006195-51fa3364bce2?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjI2NzI5fQ)Photo by [Jiroe](https://unsplash.com/photos/qAahMC9xLmA?utm_source=dropbox_paper&utm_medium=referral)

What we‚Äôve discussed so far is only half of the story. GPT works well across a multitude of tasks only because of the other innovation ‚Äî fine-tuning.

Here‚Äôs where we‚Äôre at ‚Äî we have a really good language model that (hopefully) has learned dynamics of the English language after being trained on a vast text corpus.

Now, in theory, if we stick a task-specific layer or two on top of the language model, we _should_ **get something that leverages the language model‚Äôs linguistic capabilities while also adapting to the task at hand.

Turns out that it‚Äôs not just theory. This method actually works. It works really well. Well enough to beat state of the art on a suite of NLP benchmarks. Well enough to be hailed as [NLP‚Äôs ImageNet moment](https://thegradient.pub/nlp-imagenet/).

## A Small Step for Man, a Giant Leap for Language Model-kind

![Photo by History in HD](https://images.unsplash.com/photo-1541873676-a18131494184?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjI2NzI5fQ)Photo by [History in HD](https://unsplash.com/photos/e5eDHbmHprg?utm_source=dropbox_paper&utm_medium=referral)

GPT was great. But not for long. Another similar approach ‚Äî BERT was introduced by the google language team right after GPT came out, and like a kid in a candy store, the NLP folks sent GPT to the grave. RIP.

But not for long. OpenAI quickly bounced back with a revolutionary idea ‚Äî doing absolutely nothing at all.

You see, what made BERT so great was that it used what‚Äôs called a bidirectional language model, as opposed to GPT‚Äôs unidirectional language model. I‚Äôm not going to specifically address why bidirectional models are better than unidirectional models, but when has ‚Äúbi-‚Äù anything been worse than ‚Äúuni-‚Äù something?

Here‚Äôs how I imagine the discussion at the OpenAI boardroom probably went on the day the BERT paper was published:

**Manager:** ‚ÄúHmm‚Ä¶ this BERT thing seems to be working better than our idea. What gives?‚Äù

**Random Engineer 1:** ‚ÄúWell, they did this thing called masked language modeling, where they hid a certain percentage of words and trained a language model to predict them. That allowed them to use a bidirectional model which deeply encodes‚Ä¶‚Äù

**Manager:** ‚ÄúIn English, please.‚Äù

**Random Engineer 1:** ‚ÄúTheir model is essentially ours with an extra pair of eyes on the back of its head.‚Äù

**Manager:** ‚ÄúSo the all-important question: how do we beat Mr. Sesame Street?‚Äù

**Random Engineer 2:** ‚ÄúWe could train a bidirectional model too. But that would just be copying them. Or maybe we could concatenate‚Ä¶‚Äù

**Random Engineer 1:** ‚ÄúNah. That would just take another step in an endless cycle. If they came up with BERT, they‚Äôd probably do something better eventually. We need a more long term solution.‚Äù

**Intern:** ‚ÄúYou know, we could just throw more GPUs and data at it.‚Äù

**All thee in unison:** ‚ÄúGenius!‚Äù

## The Front Page of the Internet

![Photo by Con Karampelas](https://images.unsplash.com/photo-1543185396-518db4b5faef?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjI2NzI5fQ)Photo by [Con Karampelas](https://unsplash.com/photos/o2gf2PF794w?utm_source=dropbox_paper&utm_medium=referral)

Instead of trying to beat BERT at its own game, the next iteration of GPT, prolifically named GPT-2, changes the very nature of the game it‚Äôs playing.

In simple terms, BERT is trained to be [very good at fill-in-the-blanks](https://towardsdatascience.com/a-i-plays-mad-libs-and-the-results-are-terrifying-78fa44e7f04e), while GPT-2 is trained to be very good at writing essays.

![](https://paper-attachments.dropbox.com/s_972195A84441142620E4C92312EA63C9665C3A86AFFD1D713034FA568ADFC5F9_1555424144125_openai-transformer-language-modeling.png)GPT-2 predicts the next word![](https://paper-attachments.dropbox.com/s_972195A84441142620E4C92312EA63C9665C3A86AFFD1D713034FA568ADFC5F9_1555424126367_BERT-language-modeling-masked-lm.png)BERT predicts missing (masked) words

I should also point out that what makes GPT-2 worthy of the ‚Äú2‚Äù is massive scale. While BERT has a respectable 340 million parameters, GPT-2 blows it out of the water with a whopping 1.5 billion parameters.

> Since our work on "Semi-supervised sequence learning", ELMo, BERT and others have shown changes in the algorithm give big accuracy gains. But now given these nice results with a vanilla language model, it's possible that a big factor for gains can come from scale. Exciting! <https://t.co/fL4acZE2Cn>
> 
> -- Quoc Le (@quocleix) [February 18, 2019](https://twitter.com/quocleix/status/1097580818635997184?ref_src=twsrc%5Etfw)

It also happens to be trained on a large chunk of Reddit, since the author decided that this was undeniably the perfect location to obtain high quality, impeccable prose.

Specifically, OpenAI trained GPT-2 on text obtained from outbound Reddit links submitted by authors who have an authoritative karma of 3 or greater. The dataset was taken from web links, and the data is text. So, fascinatingly, they called the dataset WebText.

Since BERT was tasked with filling in blanks, there‚Äôs no way (yet) that it could GPT-2‚Äôs Shakespearean capabilities, _even if_ **it actually performed the task of language modeling better.

So great. We now have an algorithm capable of generating coherent _sounding_ text. And I‚Äôd like to emphasize _sounding_ because the reality is that [GPT-2 generated text only makes sense if you‚Äôre not paying attention](https://srconstantin.wordpress.com/2019/02/25/humans-who-are-not-concentrating-are-not-general-intelligences/).

Both methods aim to create large and powerful pretrained language models that are useful in a transfer learning context, but GPT-2 had a hidden superpower that was guaranteed to drive media outlets wild ‚Äî writing articles about talking, four-horned, half-breed unicorns in the Andes‚Ä¶

# Making Sense if it All

If you‚Äôve read this article completely and still feel like you don‚Äôt have GPT-2 engrained in your bones, fear not.

We all understand better when we actually see the code running before our eyes. So here it is, your chance to see GPT-2 (powered by[ Hugging Face‚Äôs pretrained PyTorch model](https://github.com/huggingface/pytorch-pretrained-BERT)) running in real time, right before your eyes.

[ ![Run](https://static.floydhub.com/button/button.svg) ](https://floydhub.com/run?template=https://github.com/iyaja/GPT-	2-PyTorch)

# Further Reading

Thanks for reading my article. Hopefully, you now understand the key ideas behind one of the most significant NLP breakthroughs of 2019, beyond just the media hype.

While I was writing this, I came across many great resources that I think you‚Äôll find useful, considering that you made it this far. So here you go. Happy learning.

## Fun Stuff

  * The team at the Allen institute have put together a really cool [interactive GPT-2 demo](https://gpt2.apps.allenai.org/?text=Who%20is%20)!
  * Hugging Face created an interactive text generation editor based on GPT-2, here: [https://transformer.huggingface.co](https://transformer.huggingface.co/)
  * [ELMo](https://allennlp.org/elmo) is another fairly recent NLP techniques that I wanted to discuss, but it's not immediately relevant in the context of GPT-2.

## Technical Papers

  * The idea of transfer learning in NLP isn't entirely new. Semi-supervised sequence learning can be thought of as [the paper that birthed NLP transfer learning](https://arxiv.org/abs/1511.01432).
  * If you're interested learning about how exactly the art of fine-tuning language models developed, look no further than [the ULMFiT paper](https://arxiv.org/abs/1801.06146).
  * As I mentioned in the article, GPT-2 is the second iteration in generative pretrained transformer saga. If you want the first chapter in the story, check out [the first GPT paper](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) and [OpenAI's official blogpost](https://openai.com/blog/language-unsupervised/).
  * Remember the other model that I talked about? The one that"competed" with GPT-2? You can learn more about how that works from [the BERT paper](https://arxiv.org/abs/1810.04805).
  * Finally, the best resources to truly grasp the intricacies of GPT-2 would be [the GPT-2 paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) and [the official blogpost](https://openai.com/blog/better-language-models/).

* * *

Just a few weeks before I started writing this article, I couldn't have known that an AI breakthrough was right around the corner. Yet, a few days and a few hyperlinks later, I, a random high school graduate halfway across the globe, was looking at research produced by a world-class organization with over 1 billion dollars in total investments.

Dear internet, thank you for making great things accessible.

And if you felt that this article provided any value to you at all, the credit goes to [Alessio Gozzoli](https://www.linkedin.com/in/alessio-gozzoli-530aa2109/) and the wonderful [FloydHub AI writer](https://floydhub.github.io/write-for-floydhub/) program. FloydHub, thank you for helping me learn far more than I could have alone.

* * *

### Last update on GPT-2 (August 2019)

[OpenAI published a follow-up blog post](https://openai.com/blog/gpt-2-6-month-follow-up/) 6 months after this first release, meanwhile a group of researchers has successfully [reproduced the full training for the 1.5B GPT-2 model](https://medium.com/@vanya_cohen/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc) and released the weights!

> OpenGPT-2: We Replicated GPT-2 Because You Can Too! 1.5B Model Weights Released.  
>   
> Blogpost: <https://t.co/dqfjltMh5t>  
>   
> Colab: <https://t.co/sgO6Wed5a6>
> 
> -- Aaron Gokaslan (@SkyLi0n) [August 22, 2019](https://twitter.com/SkyLi0n/status/1164595634734845952?ref_src=twsrc%5Etfw)

This was unexpected!

* * *

### Last update on GPT-2 (November 2019)

We are at the end of this amazing journey, finally after 9 months the full GPT-2 model is [here](https://github.com/openai/gpt-2-output-dataset/tree/master/detector).

> We're releasing the 1.5billion parameter GPT-2 model as part of our staged release publication strategy.  
> \- GPT-2 output detection model: <https://t.co/PX3tbOOOTy>  
> \- Research from partners on potential malicious uses: <https://t.co/om28yMULL5>  
> \- More details: <https://t.co/d2JzaENiks> [pic.twitter.com/O3k28rrE5l](https://t.co/O3k28rrE5l)
> 
> -- OpenAI (@OpenAI) [November 5, 2019](https://twitter.com/OpenAI/status/1191764001434173440?ref_src=twsrc%5Etfw)

It's finally out üî•

* * *

### Do you model for living? üë©‚Äçüíª ü§ñ Be part of a ML/DL user research study and get a cool AI t-shirt every month üí•

  
We are looking for _full-time data scientists_ for a ML/DL user study. You'll be participating in a calibrated user research experiment for 45 minutes. The study will be done over a video call. We've got plenty of funny tees that you can show-off to your teammates. We'll ship you a different one every month for a year!

Click [here](https://typings.typeform.com/to/zpYrlW?utm_source=blog&utm_medium=bottom_text_gpt2&utm_campaign=full_time_ds_user_study) to learn more.

* * *

#### **FloydHub Call for AI writers**

Want to write amazing articles like Ajay and play your role in the long road to Artificial General Intelligence? [We are looking for passionate writers](https://floydhub.github.io/write-for-floydhub/?utm_source=floydhub&utm_medium=banner&utm_campaign=call_for_writers_2019), to build the world's best blog for practical applications of groundbreaking A.I. techniques. FloydHub has a large reach within the AI community and with your help, we can inspire the next wave of AI. [Apply now](https://goo.gl/forms/PbOw0VmUnOfO1Lxp1) and join the crew!

* * *

**About Ajay Uppili Arasanipalai**

Ajay is a deep learning enthusiast and student at the University of Illinois at Urbana-Champaign. Ajay is a [FloydHub AI Writer](https://floydhub.github.io/write-for-floydhub/). He writes technical articles for blogs like FloydHub, freecodecamp, HackerNoon, and his own blog, [Elliptigon](https://ajay.elliptigon.com). You can connect with Ajay via [LinkedIn](https://www.linkedin.com/in/ajay-arasanipalai-712911164/), [Twitter](https://twitter.com/iyajainfinity), [Medium](https://medium.com/@ajayuppili), [Facebook](https://www.facebook.com/ajay.arasanipalai), [Reddit](https://www.reddit.com/user/iyaja), and [GitHub](https://github.com/iyaja).